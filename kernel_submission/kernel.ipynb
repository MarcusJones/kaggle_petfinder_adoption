{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sun Jun 10 10:32:09 2018\n",
    "\n",
    "@author: m.jones\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install git+https://github.com/MarcusJones/kaggle_utils.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "title": "==========================================================================="
   },
   "outputs": [],
   "source": [
    "# Logging\n",
    "# =============================================================================\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "#Delete Jupyter notebook root logger handler\n",
    "logger = logging.getLogger()\n",
    "logger.handlers = []\n",
    "\n",
    "# Set level\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Create formatter\n",
    "#FORMAT = \"%(asctime)s - %(levelno)-3s - %(module)-10s  %(funcName)-10s: %(message)s\"\n",
    "#FORMAT = \"%(asctime)s - %(levelno)-3s - %(funcName)-10s: %(message)s\"\n",
    "#FORMAT = \"%(asctime)s - %(funcName)-10s: %(message)s\"\n",
    "FORMAT = \"%(asctime)s : %(message)s\"\n",
    "DATE_FMT = \"%Y-%m-%d %H:%M:%S\"\n",
    "#DATE_FMT = \"%H:%M:%S\"\n",
    "formatter = logging.Formatter(FORMAT, DATE_FMT)\n",
    "\n",
    "# Create handler and assign\n",
    "handler = logging.StreamHandler(sys.stderr)\n",
    "handler.setFormatter(formatter)\n",
    "logger.handlers = [handler]\n",
    "logging.info(\"Logging started\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import importlib.util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "title": "Globals"
   },
   "outputs": [],
   "source": [
    "#\n",
    "# LANDSCAPE_A3 = (16.53, 11.69)\n",
    "# PORTRAIT_A3 = (11.69, 16.53)\n",
    "# LANDSCAPE_A4 = (11.69, 8.27)\n",
    "if 'KAGGLE_WORKING_DIR' in os.environ:\n",
    "    DEPLOYMENT = 'Kaggle'\n",
    "else:\n",
    "    DEPLOYMENT = 'Local'\n",
    "logging.info(\"Deployment: {}\".format(DEPLOYMENT))\n",
    "if DEPLOYMENT=='Kaggle':\n",
    "    PATH_DATA_ROOT = Path.cwd() / '..' / 'input'\n",
    "    SAMPLE_FRACTION = 1\n",
    "    # import transformers as trf\n",
    "    FLAG_LOAD_TRANSFORMER = True\n",
    "if DEPLOYMENT == 'Local':\n",
    "    PATH_DATA_ROOT = r\"~/DATA/petfinder_adoption\"\n",
    "    PATH_KAGGLE_UTILS = Path(r\"../../../kaggle_utils/kaggle_utils\").absolute().resolve()\n",
    "    logging.info(\"PATH_KAGGLE_UTILS={}\".format(PATH_KAGGLE_UTILS))\n",
    "    sys.path.append(PATH_KAGGLE_UTILS)\n",
    "    import kaggle_utils.transformers as trf\n",
    "    SAMPLE_FRACTION = 1\n",
    "    FLAG_LOAD_TRANSFORMER = False\n",
    "\n",
    "\n",
    "# PATH_OUT = r\"/home/batman/git/hack_sfpd1/Out\"\n",
    "# PATH_OUT_KDE = r\"/home/batman/git/hack_sfpd1/out_kde\"\n",
    "# PATH_REPORTING = r\"/home/batman/git/hack_sfpd1/Reporting\"\n",
    "# PATH_MODELS = r\"/home/batman/git/hack_sfpd4/models\"\n",
    "# TITLE_FONT = {'fontname': 'helvetica'}\n",
    "\n",
    "\n",
    "# TITLE_FONT_NAME = \"Arial\"\n",
    "# plt.rc('font', family='Helvetica')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "title": "==========================================================================="
   },
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "# =============================================================================\n",
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import zipfile\n",
    "from datetime import datetime\n",
    "import gc\n",
    "import time\n",
    "from pprint import pprint\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "title": "==========================================================================="
   },
   "outputs": [],
   "source": [
    "# ML imports\n",
    "# =============================================================================\n",
    "import numpy as np\n",
    "print('numpy', np.__version__)\n",
    "import pandas as pd\n",
    "print('pandas', pd.__version__)\n",
    "import sklearn as sk\n",
    "print('sklearn', sk.__version__)\n",
    "\n",
    "import sklearn.preprocessing\n",
    "import sklearn.model_selection\n",
    "import sklearn.metrics\n",
    "import sklearn.linear_model\n",
    "import sklearn.pipeline\n",
    "import sklearn.model_selection\n",
    "import sklearn.ensemble\n",
    "\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "\n",
    "# Models\n",
    "import lightgbm as lgb\n",
    "print(\"lightgbm\", lgb.__version__)\n",
    "import xgboost as xgb\n",
    "print(\"xgboost\", xgb.__version__)\n",
    "# from catboost import CatBoostClassifier\n",
    "import catboost as catb\n",
    "print(\"catboost\", catb.__version__)\n",
    "\n",
    "# Metric\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "def kappa(y_true, y_pred):\n",
    "    return cohen_kappa_score(y_true, y_pred, weights='quadratic')\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "title": "==========================================================================="
   },
   "outputs": [],
   "source": [
    "# Custom imports\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is to work around kaggle kernel's not allowing external modules\n",
    "if FLAG_LOAD_TRANSFORMER:\n",
    "\n",
    "    def timeit(method):\n",
    "        \"\"\" Decorator to time execution of transformers\n",
    "        :param method:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        def timed(*args, **kw):\n",
    "            ts = time.time()\n",
    "            result = method(*args, **kw)\n",
    "            te = time.time()\n",
    "            if 'log_time' in kw:\n",
    "                name = kw.get('log_name', method.__name__.upper())\n",
    "                kw['log_time'][name] = int((te - ts) * 1000)\n",
    "            else:\n",
    "                print(\"\\t {} {:2.1f}s\".format(method.__name__, (te - ts)))\n",
    "            return result\n",
    "\n",
    "        return timed\n",
    "\n",
    "    class TransformerLog():\n",
    "        \"\"\"Add a .log attribute for logging\n",
    "        \"\"\"\n",
    "\n",
    "        @property\n",
    "        def log(self):\n",
    "            return \"Transformer: {}\".format(type(self).__name__)\n",
    "\n",
    "    class MultipleToNewFeature(sk.base.BaseEstimator, sk.base.TransformerMixin, TransformerLog):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "\n",
    "        def __init__(self, selected_cols, new_col_name, func):\n",
    "            self.selected_cols = selected_cols\n",
    "            self.new_col_name = new_col_name\n",
    "            self.func = func\n",
    "\n",
    "        def fit(self, X, y=None):\n",
    "            return self\n",
    "\n",
    "        @timeit\n",
    "        def transform(self, df, y=None):\n",
    "            # print(dMultipleToNewFeaturef)\n",
    "            df[self.new_col_name] = df.apply(self.func, axis=1)\n",
    "            print(self.log, \"{}({}) -> ['{}']\".format(self.func.__name__, self.selected_cols, self.new_col_name))\n",
    "            return df\n",
    "\n",
    "    class NumericalToCat(sk.base.BaseEstimator, sk.base.TransformerMixin):\n",
    "        \"\"\"Convert numeric indexed column into dtype category with labels\n",
    "        Convert a column which has a category, presented as an Integer\n",
    "        Initialize with a dict of ALL mappings for this session, keyed by column name\n",
    "        (This could be easily refactored to have only the required mapping)\n",
    "        \"\"\"\n",
    "\n",
    "        def __init__(self, label_map_dict, allow_more_labels=False):\n",
    "            self.label_map_dict = label_map_dict\n",
    "            self.allow_more_labels = allow_more_labels\n",
    "\n",
    "        def fit(self, X, y=None):\n",
    "            return self\n",
    "\n",
    "        def get_unique_values(self, this_series):\n",
    "            return list(this_series.value_counts().index)\n",
    "\n",
    "        def transform(self, this_series):\n",
    "            if not self.allow_more_labels:\n",
    "                if len(self.label_map_dict) > len(this_series.value_counts()):\n",
    "                    msg = \"{} labels provided, but {} values in column!\\nLabels:{}\\nValues:{}\".format(\n",
    "                        len(self.label_map_dict), len(this_series.value_counts()), self.label_map_dict,\n",
    "                        self.get_unique_values(this_series), )\n",
    "                    raise ValueError(msg)\n",
    "\n",
    "            if len(self.label_map_dict) < len(this_series.value_counts()):\n",
    "                raise ValueError\n",
    "\n",
    "            assert type(this_series) == pd.Series\n",
    "            # assert this_series.name in self.label_map_dict, \"{} not in label map!\".format(this_series.name)\n",
    "            return_series = this_series.copy()\n",
    "            # return_series = pd.Series(pd.Categorical.from_codes(this_series, self.label_map_dict))\n",
    "            return_series = return_series.astype('category')\n",
    "            return_series.cat.rename_categories(self.label_map_dict, inplace=True)\n",
    "            # print(return_series.cat.categories)\n",
    "\n",
    "            assert return_series.dtype == 'category'\n",
    "            return return_series\n",
    "\n",
    "        def get_unique_values(self, this_series):\n",
    "            return list(this_series.value_counts().index)\n",
    "\n",
    "        def transform(self, this_series):\n",
    "            if not self.allow_more_labels:\n",
    "                if len(self.label_map_dict) > len(this_series.value_counts()):\n",
    "                    msg = \"{} labels provided, but {} values in column!\\nLabels:{}\\nValues:{}\".format(\n",
    "                        len(self.label_map_dict), len(this_series.value_counts()), self.label_map_dict,\n",
    "                        self.get_unique_values(this_series), )\n",
    "                    raise ValueError(msg)\n",
    "\n",
    "            if len(self.label_map_dict) < len(this_series.value_counts()):\n",
    "                raise ValueError\n",
    "\n",
    "            assert type(this_series) == pd.Series\n",
    "            # assert this_series.name in self.label_map_dict, \"{} not in label map!\".format(this_series.name)\n",
    "            return_series = this_series.copy()\n",
    "            # return_series = pd.Series(pd.Categorical.from_codes(this_series, self.label_map_dict))\n",
    "            return_series = return_series.astype('category')\n",
    "            return_series.cat.rename_categories(self.label_map_dict, inplace=True)\n",
    "            # print(return_series.cat.categories)\n",
    "\n",
    "            assert return_series.dtype == 'category'\n",
    "            return return_series\n",
    "\n",
    "    # Here we simulate a module namespace\n",
    "    class trf:\n",
    "        NumericalToCat = NumericalToCat\n",
    "        MultipleToNewFeature = MultipleToNewFeature\n",
    "        TransformerLog = TransformerLog\n",
    "        timeit = timeit\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "title": "==========================================================================="
   },
   "outputs": [],
   "source": [
    "# Data source and paths\n",
    "# =============================================================================\n",
    "path_data = Path(PATH_DATA_ROOT, r\"\").expanduser()\n",
    "assert path_data.exists(), \"Data path does not exist: {}\".format(path_data)\n",
    "logging.info(\"Data path {}\".format(PATH_DATA_ROOT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "title": "==========================================================================="
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "# =============================================================================\n",
    "logging.info(f\"Loading files into memory\")\n",
    "\n",
    "# def load_zip\n",
    "# with zipfile.ZipFile(path_data / \"train.zip\").open(\"train.csv\") as f:\n",
    "#     df_train = pd.read_csv(f, delimiter=',')\n",
    "# with zipfile.ZipFile(path_data / \"test.zip\").open(\"test.csv\") as f:\n",
    "#     df_test = pd.read_csv(f, delimiter=',')\n",
    "\n",
    "df_train = pd.read_csv(path_data / 'train'/ 'train.csv')\n",
    "df_train.set_index(['PetID'],inplace=True)\n",
    "df_test = pd.read_csv(path_data / 'test' / 'test.csv')\n",
    "df_test.set_index(['PetID'],inplace=True)\n",
    "\n",
    "breeds = pd.read_csv(path_data / \"breed_labels.csv\")\n",
    "colors = pd.read_csv(path_data / \"color_labels.csv\")\n",
    "states = pd.read_csv(path_data / \"state_labels.csv\")\n",
    "\n",
    "logging.info(\"Loaded train {}\".format(df_train.shape))\n",
    "logging.info(\"Loaded test {}\".format(df_test.shape))\n",
    "\n",
    "# Add a column to label the source of the data\n",
    "df_train['dataset_type'] = 'train'\n",
    "df_test['dataset_type'] = 'test'\n",
    "\n",
    "# Set this aside for debugging\n",
    "#TODO: Remove later\n",
    "original_y_train = df_train['AdoptionSpeed'].copy()\n",
    "original_y_train.value_counts()\n",
    "\n",
    "logging.info(\"Added dataset_type column for origin\".format())\n",
    "df_all = pd.concat([df_train, df_test], sort=False)\n",
    "# df_all.set_index('PetID',inplace=True)\n",
    "\n",
    "del df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "title": "Memory of the training DF:"
   },
   "outputs": [],
   "source": [
    "logging.info(\"Size of df_all: {} MB\".format(sys.getsizeof(df_all) / 1000 / 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['PhotoAmt'] = df_all['PhotoAmt'].astype('int')\n",
    "# df_all['AdoptionSpeed'] = df_all['AdoptionSpeed'].fillna(-1)\n",
    "# df_all['AdoptionSpeed'] = df_all['AdoptionSpeed'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "title": "Category Mappings"
   },
   "outputs": [],
   "source": [
    "label_maps = dict()\n",
    "label_maps['Vaccinated'] = {\n",
    "    1 : 'Yes',\n",
    "    2 : 'No',\n",
    "    3 : 'Not sure',\n",
    "}\n",
    "label_maps['Type'] = {\n",
    "    1:\"Dog\",\n",
    "    2:\"Cat\"\n",
    "}\n",
    "label_maps['AdoptionSpeed'] = {\n",
    "    # -1 : \"Empty\",\n",
    "    0 : \"same day\",\n",
    "    1 : \"between 1 and 7 days\",\n",
    "    2 : \"between 8 and 30 days\",\n",
    "    3 : \"between 31 and 90 days\",\n",
    "    4 : \"No adoption after 100 days\",\n",
    "}\n",
    "label_maps['Gender'] = {\n",
    "    1 : 'Male',\n",
    "    2 : 'Female',\n",
    "    3 : 'Group',\n",
    "}\n",
    "label_maps['MaturitySize'] = {\n",
    "    1 : 'Small',\n",
    "    2 : 'Medium',\n",
    "    3 : 'Large',\n",
    "    4 : 'Extra Large',\n",
    "    0 : 'Not Specified',\n",
    "}\n",
    "label_maps['FurLength'] = {\n",
    "    1 : 'Short',\n",
    "    2 : 'Medium',\n",
    "    3 : 'Long',\n",
    "    0 : 'Not Specified',\n",
    "}\n",
    "label_maps['Dewormed'] = {\n",
    "    1 : 'Yes',\n",
    "    2 : 'No',\n",
    "    3 : 'Not sure',\n",
    "}\n",
    "label_maps['Sterilized'] = {\n",
    "    1 : 'Yes',\n",
    "    2 : 'No',\n",
    "    3 : 'Not sure',\n",
    "}\n",
    "label_maps['Health'] = {\n",
    "    1 : 'Healthy',\n",
    "    2 : 'Minor Injury',\n",
    "    3 : 'Serious Injury',\n",
    "    0 : 'Not Specified',\n",
    "}\n",
    "\n",
    "# For the breeds, load the two types seperate\n",
    "dog_breed = breeds[['BreedID','BreedName']][breeds['Type']==1].copy()\n",
    "map_dog_breed = dict(zip(dog_breed['BreedID'], dog_breed['BreedName']))\n",
    "\n",
    "cat_breed = breeds[['BreedID','BreedName']][breeds['Type']==2].copy()\n",
    "map_cat_breed = dict(zip(cat_breed['BreedID'], cat_breed['BreedName']))\n",
    "\n",
    "# Just in case, check for overlap in breeds\n",
    "# for i in range(308):\n",
    "#     print(i,end=\": \")\n",
    "#     if i in map_dog_breed: print(map_dog_breed[i], end=' - ')\n",
    "#     if i in map_cat_breed: print(map_cat_breed[i], end=' - ')\n",
    "#     if i in map_dog_breed and i in map_cat_breed: raise\n",
    "#     print()\n",
    "\n",
    "# It's fine, join them into one dict\n",
    "map_all_breeds = dict()\n",
    "map_all_breeds.update(map_dog_breed)\n",
    "map_all_breeds.update(map_cat_breed)\n",
    "map_all_breeds[0] = \"NA\"\n",
    "\n",
    "# Now add them to the master label dictionary for each column\n",
    "label_maps['Breed1'] = map_all_breeds\n",
    "label_maps['Breed2'] = map_all_breeds\n",
    "\n",
    "# Similarly, load the color map\n",
    "map_colors = dict(zip(colors['ColorID'], colors['ColorName']))\n",
    "map_colors[0] = \"NA\"\n",
    "label_maps['Color1'] = map_colors\n",
    "label_maps['Color2'] = map_colors\n",
    "label_maps['Color3'] = map_colors\n",
    "\n",
    "# And the states map\n",
    "label_maps['State'] = dict(zip(states['StateID'], states['StateName']))\n",
    "\n",
    "logging.info(\"Category mappings for {} columns created\".format(len(label_maps)))\n",
    "\n",
    "for map in label_maps:\n",
    "    print(map, label_maps[map])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "Dynamically create the transformation definitions"
   },
   "outputs": [],
   "source": [
    "# tx_definitions_preview = [(col_name, label_maps[col_name]) for col_name in label_maps]\n",
    "# for t in tx_definitions_preview:\n",
    "#     print(t)\n",
    "tx_definitions = [(col_name, trf.NumericalToCat(label_maps[col_name], True)) for col_name in label_maps]\n",
    "# col_name = 'Vaccinated'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "title": "Pipeline"
   },
   "outputs": [],
   "source": [
    "# Build the pipeline\n",
    "# NOTES:\n",
    "# input_df - Ensure the passed in column enters as a series or DF\n",
    "# df_out - Ensure the pipeline returns a df\n",
    "# default - if a column is not transformed, keep it unchanged!\n",
    "# WARNINGS:\n",
    "# The categorical dtype is LOST!\n",
    "# The mapping does NOT match the original!\n",
    "# Do NOT use DataFrameMapper for creating new columns, use a regular pipeline!\n",
    "data_mapper = DataFrameMapper(\n",
    "    tx_definitions,\n",
    "input_df=True, df_out=True, default=None)\n",
    "logging.info(\"Categorical transformer pipeline warnings, see docstring!\".format())\n",
    "\n",
    "# print(\"DataFrameMapper, applies transforms directly selected columns\")\n",
    "# for i, step in enumerate(data_mapper.features):\n",
    "#     print(i, step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "title": "FIT TRANSFORM"
   },
   "outputs": [],
   "source": [
    "df_all = data_mapper.fit_transform(df_all)\n",
    "logging.info(\"Size of train df_all with categorical columns: {} MB\".format(sys.getsizeof(df_all)/1000/1000))\n",
    "logging.info(\"Warning: PipeLine returns strings, not categorical! \".format(sys.getsizeof(df_all)/1000/1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "title": "WARNING - sklearn-pandas has a flaw, it does not preserve categorical features!!!"
   },
   "outputs": [],
   "source": [
    "# ordered = ['AdoptionSpeed','MaturitySize','FurLength','Health'] #Actually, most have 'unspecified', which can't be ordered\n",
    "ordered_cols = ['AdoptionSpeed']\n",
    "for col in label_maps:\n",
    "    this_labels = sorted(list(label_maps[col].items()), key=lambda tup: tup[0])\n",
    "    listed_categories = [tup[1] for tup in this_labels]\n",
    "    if col in listed_categories:\n",
    "        ordered_flag = True\n",
    "    else:\n",
    "        ordered_flag = False\n",
    "    cat_type = pd.api.types.CategoricalDtype(categories=listed_categories,ordered=True)\n",
    "    df_all[col] = df_all[col].astype(cat_type)\n",
    "\n",
    "logging.info(\"Reapplied categorical features\".format())\n",
    "logging.info(\"Size of df_all with categorical features: {} MB\".format(sys.getsizeof(df_all)/1000/1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# df_all['AdoptionSpeed'].value_counts()\n",
    "# ser = df_all['AdoptionSpeed']\n",
    "#\n",
    "# original_y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "SUMMARY"
   },
   "outputs": [],
   "source": [
    "\n",
    "logging.info(\"Final shape of df_all {}\".format(df_all.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "DONE HERE - DELETE UNUSED"
   },
   "outputs": [],
   "source": [
    "print(\"******************************\")\n",
    "\n",
    "del_vars =[\n",
    "    'breeds',\n",
    "    'cat_breed',\n",
    "    'colors',\n",
    "    'data_mapper',\n",
    "    'dog_breed',\n",
    "    'map_colors',\n",
    "    'map_all_breeds',\n",
    "    'map_cat_breed',\n",
    "    'map_dog_breed',\n",
    "    'states',\n",
    "]\n",
    "cnt = 0\n",
    "for name in dir():\n",
    "    if name in del_vars:\n",
    "        cnt+=1\n",
    "        del globals()[name]\n",
    "logging.info(f\"Removed {cnt} variables from memory\")\n",
    "del cnt, name, del_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "title": "==========================================================================="
   },
   "outputs": [],
   "source": [
    "# Feature\n",
    "# =============================================================================\n",
    "def pure_breed(row):\n",
    "    # print(row)\n",
    "    mixed_breed_keywords = ['domestic', 'tabby', 'mixed']\n",
    "\n",
    "    # Mixed if labelled as such\n",
    "    if row['Breed1'] == 'Mixed Breed':\n",
    "        return False\n",
    "\n",
    "    # Possible pure if no second breed\n",
    "    elif row['Breed2'] == 'NA':\n",
    "        # Reject domestic keywords\n",
    "        if any([word in row['Breed1'].lower() for word in mixed_breed_keywords]):\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "title": "Build the pipeline"
   },
   "outputs": [],
   "source": [
    "this_pipeline = sk.pipeline.Pipeline([\n",
    "        ('feat: Pure Breed', trf.MultipleToNewFeature(['Breed1','Breed2'], 'Pure Breed', pure_breed)),\n",
    "        ])\n",
    "\n",
    "logging.info(\"Created pipeline:\")\n",
    "for i, step in enumerate(this_pipeline.steps):\n",
    "    print(i, step[0], step[1].__str__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "title": "Fit Transform"
   },
   "outputs": [],
   "source": [
    "original_cols = df_all.columns\n",
    "df_all = this_pipeline.fit_transform(df_all)\n",
    "logging.info(\"Pipeline complete. {} new columns.\".format(len(df_all.columns) - len(original_cols)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The final selection of columns from the main DF\n",
    "cols_to_use = ['Type', 'Age', 'Breed1', 'Breed2', 'Gender', 'Color1', 'Color2', 'Color3', 'MaturitySize', 'FurLength',\n",
    "               'Vaccinated', 'Dewormed', 'Sterilized', 'Health', 'Quantity', 'Fee', 'State', 'RescuerID', 'VideoAmt',\n",
    "               'PhotoAmt', 'AdoptionSpeed', 'No_name', 'Pure_breed', 'health', 'Free',\n",
    "               'score', 'magnitude']\n",
    "\n",
    "cols_to_discard = [\n",
    "    'RescuerID',\n",
    "    'Description',\n",
    "    'Name',\n",
    "]\n",
    "\n",
    "logging.info(\"Feature selection\".format())\n",
    "original_columns = df_all.columns\n",
    "# col_selection = [col for col in all_columns if col not in cols_to_discard]\n",
    "\n",
    "df_all.drop(cols_to_discard,inplace=True, axis=1)\n",
    "logging.info(\"Discarded {}\".format(cols_to_discard))\n",
    "\n",
    "logging.info(\"Selected {} of {} columns\".format(len(df_all.columns),len(original_columns)))\n",
    "logging.info(\"Size of df_all with selected features: {} MB\".format(sys.getsizeof(df_all)/1000/1000))\n",
    "\n",
    "logging.info(\"Record selection (sampling)\".format())\n",
    "logging.info(\"Sampling fraction: {}\".format(SAMPLE_FRACTION))\n",
    "# df_all = df_all.sample(frac=SAMPLE_FRACTION)\n",
    "logging.info(\"Final size of data frame: {}\".format(df_all.shape))\n",
    "logging.info(\"Size of df_all with selected features and records: {} MB\".format(sys.getsizeof(df_all)/1000/1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_tr = df_all[df_all['dataset_type']=='train'].copy()\n",
    "df_tr.drop('dataset_type', axis=1, inplace=True)\n",
    "logging.info(\"Split off train set {}, {:.1%} of the records\".format(df_tr.shape,len(df_tr)/len(df_all)))\n",
    "\n",
    "df_te = df_all[df_all['dataset_type']=='test'].copy()\n",
    "df_te.drop('dataset_type', axis=1, inplace=True)\n",
    "logging.info(\"Split off test set {}, {:.1%} of the records\".format(df_tr.shape,len(df_te)/len(df_all)))\n",
    "\n",
    "target_col = 'AdoptionSpeed'\n",
    "y_tr = df_tr[target_col]\n",
    "logging.info(\"Split off y_tr {}\".format(len(y_tr)))\n",
    "\n",
    "# Drop the target\n",
    "X_tr = df_tr.drop(['AdoptionSpeed'], axis=1)\n",
    "logging.info(\"Split off X_tr {}\".format(X_tr.shape))\n",
    "\n",
    "# Drop the target (it's NaN anyways)\n",
    "X_te = df_te.drop(['AdoptionSpeed'], axis=1)\n",
    "logging.info(\"Split off X_te {}\".format(X_te.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "DONE HERE - DELETE UNUSED"
   },
   "outputs": [],
   "source": [
    "\n",
    "del_vars =[\n",
    "    # 'df_all',\n",
    "    # 'df_tr',\n",
    "    # 'df_te',\n",
    "]\n",
    "cnt = 0\n",
    "for name in dir():\n",
    "    if name in del_vars:\n",
    "        cnt+=1\n",
    "        del globals()[name]\n",
    "logging.info(f\"Removed {cnt} variables from memory\")\n",
    "del cnt, name, del_vars\n",
    "\n",
    "#https://roamanalytics.com/2016/10/28/are-categorical-variables-getting-lost-in-your-random-forests/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# df_all['AdoptionSpeed'].fillna(-1)\n",
    "# a[pd.isnull(a)]\n",
    "import pandas.api.types as ptypes\n",
    "encoder_list = list()\n",
    "for col in X_tr.columns:\n",
    "    if ptypes.is_categorical_dtype(X_tr[col]):\n",
    "        encoder_list.append((col,sk.preprocessing.LabelEncoder()))\n",
    "\n",
    "    elif ptypes.is_string_dtype(X_tr[col]):\n",
    "        # encoder_list.append((col,'STR?'))\n",
    "        continue\n",
    "\n",
    "    elif ptypes.is_bool_dtype(X_tr[col]):\n",
    "        encoder_list.append((col, sk.preprocessing.LabelEncoder()))\n",
    "\n",
    "    elif ptypes.is_bool_dtype(X_tr[col]):\n",
    "        encoder_list.append((col,sk.preprocessing.LabelEncoder()))\n",
    "\n",
    "    elif ptypes.is_int64_dtype(X_tr[col]):\n",
    "        encoder_list.append((col,None))\n",
    "\n",
    "    elif ptypes.is_float_dtype(X_tr[col]):\n",
    "        encoder_list.append((col,None))\n",
    "\n",
    "    else:\n",
    "        print('Skip')\n",
    "\n",
    "\n",
    "trf_cols = list()\n",
    "for enc in encoder_list:\n",
    "    logging.info(\"{}\".format(enc))\n",
    "    trf_cols.append(enc[0])\n",
    "\n",
    "skipped_cols = set(X_tr.columns) - set(trf_cols)\n",
    "# print(skipped_cols)\n",
    "# encoder_list.append(('dataset_type',None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "data_mapper = DataFrameMapper(encoder_list, input_df=True, df_out=True)\n",
    "# ], input_df=True, df_out=True, default=None)\n",
    "\n",
    "for step in data_mapper.features:\n",
    "    print(step)\n",
    "\n",
    "X_te.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = data_mapper.fit_transform(X_tr.copy())\n",
    "X_te = data_mapper.fit_transform(X_te.copy())\n",
    "logging.info(\"Encoded X_tr and X_te\".format())\n",
    "y_tr = y_tr.cat.codes\n",
    "logging.info(\"Reverted target to integers\".format())\n",
    "# df_trf_head = df_all_encoded.head()\n",
    "X_te.iloc[0]# Train 2 seperate models, one for cats, one for dogs!!\n",
    "\n",
    "# assert y_tr.dtype == np.dtype('int64'), \"y_tr must be integer for LGBM!!\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "title": "Model and params"
   },
   "outputs": [],
   "source": [
    "params_model = dict()\n",
    "# params['num_class'] = len(y_tr.value_counts())\n",
    "params_model.update({\n",
    "\n",
    "})\n",
    "clf = sk.ensemble.RandomForestClassifier(**params_model )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "GridCV"
   },
   "outputs": [],
   "source": [
    "random_grid = {\n",
    "    'n_estimators': [int(x) for x in np.linspace(start = 800, stop = 1500, num = 8)],\n",
    "    'max_features' : ['auto', 'sqrt'],\n",
    "    'max_depth' : [int(x) for x in np.linspace(10, 40, num = 8)] + [None],\n",
    "    'min_samples_split' : [2, 5, 10],\n",
    "    'min_samples_leaf' : [1, 2, 4],\n",
    "    'bootstrap' : [True, ],\n",
    "    # 'bootstrap' : [True, False],\n",
    "}\n",
    "\n",
    "grid_lengths = [len(key) for key in random_grid.values()]\n",
    "grid_size = reduce(lambda x, y: x*y, grid_lengths)\n",
    "logging.info(\"Grid size {}\".format(grid_size))\n",
    "# Best parameters: {'n_estimators': 1000, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 20, 'bootstrap': True}\n",
    "\n",
    "clf_grid = sk.model_selection.RandomizedSearchCV(estimator=clf, param_distributions=random_grid,\n",
    "                               n_iter=50, cv=3, verbose=1, random_state=42, n_jobs=-1)\n",
    "\n",
    "# clf_grid = sk.model_selection.GridSearchCV(clf, params_grid,\n",
    "#                                        verbose=1,\n",
    "#                                        cv=5,\n",
    "#                                        n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "title": "Fit"
   },
   "outputs": [],
   "source": [
    "clf_grid.fit(X_tr, y_tr)\n",
    "\n",
    "# Print the best parameters found\n",
    "print(\"Best score:\", clf_grid.best_score_)\n",
    "print(\"Best parameters:\", clf_grid.best_params_)\n",
    "\n",
    "clf_grid_BEST = clf_grid.best_estimator_# %%\n",
    "# Ensure the target is unchanged\n",
    "assert all(y_tr.sort_index() == original_y_train.sort_index())\n",
    "# Ensure the target is unchanged (unshuffled!)\n",
    "assert all(y_tr == original_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "title": "Predict on X_tr for comparison"
   },
   "outputs": [],
   "source": [
    "y_tr_predicted = clf_grid_BEST.predict(X_tr)\n",
    "\n",
    "# original_y_train.value_counts()\n",
    "# y_tr.cat.codes.value_counts()\n",
    "# y_tr_predicted.value_counts()\n",
    "# y_tr.value_counts()\n",
    "\n",
    "train_kappa = kappa(y_tr, y_tr_predicted)\n",
    "\n",
    "logging.info(\"Metric on training set: {:0.3f}\".format(train_kappa))\n",
    "# these_labels = list(label_maps['AdoptionSpeed'].values())\n",
    "sk.metrics.confusion_matrix(y_tr, y_tr_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "Predict on Test set"
   },
   "outputs": [],
   "source": [
    "# NB we only want the defaulters column!\n",
    "predicted = clf_grid_BEST.predict(X_te)\n",
    "\n",
    "# raise \"Lost the sorting of y!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "title": "Open the submission"
   },
   "outputs": [],
   "source": [
    "# with zipfile.ZipFile(path_data / \"test.zip\").open(\"sample_submission.csv\") as f:\n",
    "#     df_submission = pd.read_csv(f, delimiter=',')\n",
    "df_submission_template = pd.read_csv(path_data / 'test' / 'sample_submission.csv', delimiter=',')\n",
    "df_submission = pd.DataFrame({'PetID': df_submission_template.PetID, 'AdoptionSpeed': [int(i) for i in predicted]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "title": "Collect predicitons"
   },
   "outputs": [],
   "source": [
    "df_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "title": "Create csv"
   },
   "outputs": [],
   "source": [
    "df_submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "main_language": "python",
   "text_representation": {
    "extension": ".py",
    "format_name": "percent"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
